<!DOCTYPE HTML>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<title>$1 Recognizer</title>
	<link href="styles.css" rel="stylesheet" type="text/css" />
	<!--[if IE]><script src="excanvas.js"></script><![endif]-->
	<script type="text/javascript" src="canvas.text.js"></script>
	<script type="text/javascript" src="./faces/gentilis-normal-normal.js"></script>
	<script type="text/javascript" src="./jquery-1.7.2.min.js"></script>
	<script type="text/javascript" src="dollar.js"></script>
	<script type="text/javascript"><!--
	    //
		// Startup
		//
		var _isDown, _points, _r, _g, _rc;
		function onLoadEvent()
		{
			_points = new Array();
			_r = new DollarRecognizer();

			var canvas = document.getElementById('myCanvas');
			_g = canvas.getContext('2d');
			_g.fillStyle = "rgb(0,0,225)";
			_g.strokeStyle = "rgb(0,0,225)";
			_g.lineWidth = 3;
			_g.font = "16px Gentilis";
			_rc = getCanvasRect(canvas); // canvas rect on page
			_g.fillStyle = "rgb(255,255,136)";
			_g.fillRect(0, 0, _rc.width, 20);

			_isDown = false;
		}
		function getCanvasRect(canvas)
		{
			var w = canvas.width;
			var h = canvas.height;

			var cx = canvas.offsetLeft;
			var cy = canvas.offsetTop;
			while (canvas.offsetParent != null)
			{
				canvas = canvas.offsetParent;
				cx += canvas.offsetLeft;
				cy += canvas.offsetTop;
			}
			return {x: cx, y: cy, width: w, height: h};
		}
		function getScrollX()
		{
			var scrollX = $(window).scrollLeft();
			return scrollX;
		}
		function getScrollY()
		{
			var scrollY = $(window).scrollTop();
			return scrollY;
		}
		//
		// Mouse Events
		//
		function mouseDownEvent(x, y, button)
		{
			document.onselectstart = function() { return false; } // disable drag-select
			document.onmousedown = function() { return false; } // disable drag-select
			if (button <= 1)
			{
				_isDown = true;
				x -= _rc.x - getScrollX();
				y -= _rc.y - getScrollY();
				if (_points.length > 0)
					_g.clearRect(0, 0, _rc.width, _rc.height);
				_points.length = 1; // clear
				_points[0] = new Point(x, y);
				drawText("Recording unistroke...");
				_g.fillRect(x - 4, y - 3, 9, 9);
			}
			else if (button == 2)
			{
				drawText("Recognizing gesture...");
			}
		}
		function mouseMoveEvent(x, y, button)
		{
			if (_isDown)
			{
				x -= _rc.x - getScrollX();
				y -= _rc.y - getScrollY();
				_points[_points.length] = new Point(x, y); // append
				drawConnectedPoint(_points.length - 2, _points.length - 1);
			}
		}
		function mouseUpEvent(x, y, button)
		{
			document.onselectstart = function() { return true; } // enable drag-select
			document.onmousedown = function() { return true; } // enable drag-select
			if (_isDown || button == 2)
			{
				_isDown = false;
				if (_points.length >= 10)
				{
					var result = _r.Recognize(_points, document.getElementById('useProtractor').checked);
					drawText("Result: " + result.Name + " (" + round(result.Score,2) + ") in " + result.Time + " ms.");
				}
				else // fewer than 10 points were inputted
				{
					drawText("Too few points made. Please try again.");
				}
			}
		}
		function drawText(str)
		{
			_g.fillStyle = "rgb(255,255,136)";
			_g.fillRect(0, 0, _rc.width, 20);
			_g.fillStyle = "rgb(0,0,255)";
			_g.fillText(str, 1, 14);
		}
		function drawConnectedPoint(from, to)
		{
			_g.beginPath();
			_g.moveTo(_points[from].X, _points[from].Y);
			_g.lineTo(_points[to].X, _points[to].Y);
			_g.closePath();
			_g.stroke();
		}
		function round(n, d) // round 'n' to 'd' decimals
		{
			d = Math.pow(10, d);
			return Math.round(n * d) / d;
		}
		//
		// Unistroke Adding and Clearing
		//
		function onClickAddExisting()
		{
			if (_points.length >= 10)
			{
				var unistrokes = document.getElementById('unistrokes');
				var name = unistrokes[unistrokes.selectedIndex].value;
				var num = _r.AddGesture(name, _points);
				drawText("\"" + name + "\" added. No. of \"" + name + "\" defined: " + num + ".");
			}
		}
		function onClickAddCustom()
		{
			var name = document.getElementById('custom').value;
			if (_points.length >= 10 && name.length > 0)
			{
				var num = _r.AddGesture(name, _points);
				drawText("\"" + name + "\" added. No. of \"" + name + "\" defined: " + num + ".");
			}
		}
		function onClickCustom()
		{
			document.getElementById('custom').select();
		}
		function onClickDelete()
		{
			var num = _r.DeleteUserGestures(); // deletes any user-defined unistrokes
			alert("All user-defined gestures have been deleted. Only the 1 predefined gesture remains for each of the " + num + " types.");
		}
	// -->
	</script>
</head>
<body onload="onLoadEvent()">
	<p align="center">
		Recognizers:
		<a href="http://depts.washington.edu/madlab/proj/dollar/index.html"><b style="background-color:navy;color:white;">$1</b></a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/ndollar.html">$N</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/pdollar.html">$P</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/pdollarplus.html">$P+</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/qdollar.html">$Q</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/impact.html">Impact of $-family</a>
	<br/>
		Tools:
		<a href="http://depts.washington.edu/madlab/proj/dollar/gecko.html">GECKo</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/great.html">GREAT</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/ghost.html">GHoST</a>
		&nbsp;&bull;&nbsp;
		<a href="http://depts.washington.edu/madlab/proj/dollar/agate.html">AGATe</a>
	</p>

	<div id="Mast">
		<a href="$1.png"><img style="float:right;margin-top:0em" src="$1.png" border="0" width="280" /></a>
		<p id="heading">$1 Unistroke Recognizer</p>
		<p>
		<a href="http://faculty.washington.edu/wobbrock/">Jacob O. Wobbrock</a>, University of Washington <a style="font-size:8pt" href="mailto:Jacob O. Wobbrock &lt;wobbrock@uw.edu&gt;?subject=From the $1 recognizer page">[contact]</a><br/>
		<a href="http://research.microsoft.com/en-us/um/people/awilson/">Andrew D. Wilson</a>, Microsoft Research<br/>
		<a href="http://research.google.com/pubs/author38946.html">Yang Li</a>, University of Washington<sup>&dagger;</sup>
		</p>
		<p style="font-size:8pt"><sup>&dagger;</sup>Currently at Google</p>
	</div>
	<div id="Content">
		<p class="subhead">Download</p>
		<p>$1 source code: <a href="dollar.js">JavaScript</a>, <a href="dollar.zip">C#</a><br/>
		   Dynamic time warping: <a href="dtw.zip">C#</a><br/>
		   Rubine classifier: <a href="rubine.zip">C#</a><br/>
		   Pseudocode: <a href="dollar.pdf">$1</a>, <a href="protractor.pdf">Protractor</a><br/>
		   Unistroke gesture logs: <a href="xml.zip">XML</a><br/>
		   Paper: <a href="http://faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf">PDF</a>
		</p>
		<p>This software is distributed under the <a href="http://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_.28.22Revised_BSD_License.22.2C_.22New_BSD_License.22.2C_or_.22Modified_BSD_License.22.29">New BSD License</a> agreement.</p>

		<p class="subhead">About</p>
		<p>
			The <b>$1 Unistroke Recognizer</b> is a 2-D single-stroke recognizer designed for rapid prototyping of gesture-based
			user interfaces. In machine learning terms, $1 is an instance-based nearest-neighbor classifier with a 2-D Euclidean
			distance function, i.e., a geometric template matcher. $1 is a significant extension of the proportional shape matching
			approach used in <a href="http://dl.acm.org/citation.cfm?id=1029640">SHARK<sup>2</sup></a>, which itself is
			an adaptation of <a href="http://dl.acm.org/citation.cfm?id=1664979">Tappert's elastic matching</a> approach
			with zero look-ahead. Despite its simplicity, $1 requires very few templates to perform well and is only about
			100 lines of code, making it easy to deploy.
			An optional enhancement called <a href="http://dl.acm.org/citation.cfm?id=1753654">Protractor</a> improves $1's speed.
		</p>
		<p>
			The <a href="ndollar.html">$N Multistroke Recognizer</a> extends $1 to gestures with multiple strokes.
			The <a href="pdollar.html">$P Point-Cloud Recognizer</a> performs unistroke and multistroke recognition without the
			combinatoric overhead of $N, as it ignores stroke number, order, and direction. The <a href="qdollar.html">$Q Super-Quick Recognizer</a>
			extends $P for use on low-powered mobiles and wearables, as it is a whopping 142&times; faster and slightly more accurate.
		</p>
		<p>The $-family recognizers have been built into numerous projects and even industry prototypes,
		   and have had many follow-ons by others. <a href="impact.html">Read about the $-family's impact.</a>
		</p>

		<p class="subhead">Demo</p>
		<p>
			In the demo below, only one unistroke template is loaded for each of the 16 gesture types. You can add additional
			unistrokes as you wish, and even define your own custom unistrokes.
			<!-- Gesture image and canvas -->
			<table border="0" cellspacing="10">
				<tr>
					<td valign="top">
						<img src="unistrokes.gif"><br/>
						<p>
							<form style="font-size:10pt">
								<input type="radio" name="search" id="useGSS" checked>
									<span style="font-weight:bold">Use Golden Section Search <i>(original)</i></span>
								</input><br />
								<input type="radio" name="search" id="useProtractor">
									<span style="font-weight:bold">Use Protractor <i>(faster)</i></span>
								</input>
							</form>
						</p>
					</td>
					<td valign="top" align="left">
						<p style="margin-bottom:4pt;font-size:10pt"><i>Make strokes on this canvas. If a misrecognition occurs,
						add the misrecognized unistroke as an example of the intended gesture.</i>
						</p>

						<canvas id="myCanvas" width="420" height="400" style="background-color:#dddddd"
								onmousedown="mouseDownEvent(event.clientX, event.clientY, event.button)"
								onmousemove="mouseMoveEvent(event.clientX, event.clientY, event.button)"
								onmouseup="mouseUpEvent(event.clientX, event.clientY, event.button)"
								oncontextmenu="return false;">
							<span style="background-color:#ffff88;">The &lt;canvas&gt; element is not supported by this browser.</span>
						</canvas>

						<!-- Editing area below stroking canvas area -->
						<table border="0" width="420" style="font-size:10pt">
							<tr>
								<td valign="top" align="left">Add as example of existing type:</td>
								<td valign="top" align="right">
									<select id="unistrokes" style="width:136px" onkeypress="if (event.keyCode == 13) onClickAddExisting()">
										<option selected value="triangle">triangle</option>
										<option value="x">x</option>
										<option value="rectangle">rectangle</option>
										<option value="circle">circle</option>
										<option value="check">check</option>
										<option value="caret">caret</option>
										<option value="zig-zag">zig-zag</option>
										<option value="arrow">arrow</option>
										<option value="left square bracket">left square bracket</option>
										<option value="right square bracket">right square bracket</option>
										<option value="v">v</option>
										<option value="delete">delete</option>
										<option value="left curly brace">left curly brace</option>
										<option value="right curly brace">right curly brace</option>
										<option value="star">star</option>
										<option value="pigtail">pigtail</option>
									</select>
								</td>
								<td valign="top" align="right"><input type="button" style="width:64px" value="  Add   " onclick="onClickAddExisting()" /></td>
							</tr>
							<tr>
								<td valign="top" align="left">Add as example of custom type:</td>
								<td valign="top" align="right"><input type="text" id="custom" style="width:130px" value="Type name here..." onclick="onClickCustom()" onkeypress="if (event.keyCode == 13) onClickAddCustom()" /></td>
								<td valign="top" align="right"><input type="button" style="width:64px" value="  Add   " onclick="onClickAddCustom()" /></td>
							</tr>
							<tr>
								<td valign="top" align="left">Delete all user-defined gestures:</td>
								<td valign="top" align="right">&nbsp;</td>
								<td valign="top" align="right"><input type="button" style="width:64px" value="Delete" onclick="onClickDelete()" /></td>
							</tr>
						</table>
						<!-- End of editing area below stroking canvas area -->
					</td>
				</tr>
			</table>
		</p>

		<p class="subhead">Our Gesture Software Projects</p>
		<p>
			<ul>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/qdollar.html">$Q</a>: Super-quick multistroke recognizer - optimized for low-power mobiles and wearables</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/pdollarplus.html">$P+</a>: Point-cloud multistroke recognizer - optimized for people with low vision</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/pdollar.html">$P</a>: Point-cloud multistroke recognizer - for recognizing multistroke gestures as point-clouds</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/ndollar.html">$N</a>: Multistroke recognizer - for recognizing simple multistroke gestures</li>
				<li style="background-color:lightyellow"><a href="http://depts.washington.edu/madlab/proj/dollar/index.html">$1</a>: Unistroke recognizer - for recognizing unistroke gestures</li>
			</ul>
			<ul>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/agate.html">AGATe</a>: AGreement Analysis Toolkit - for calculating agreement in gesture-elicitation studies</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/ghost.html">GHoST</a>: Gesture HeatmapS Toolkit - for visualizing variation in gesture articulation</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/great.html">GREAT</a>: Gesture RElative Accuracy Toolkit - for measuring variation in gesture articulation</li>
				<li><a href="http://depts.washington.edu/madlab/proj/dollar/gecko.html">GECKo</a>: GEsture Clustering toolKit - for clustering gestures and calculating agreement</li>
			</ul>
		</p>

		<p class="subhead">Our Gesture Publications</p>
		<ol>
		<li style="font-size:10pt;">
			Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2018).
			<a href="http://faculty.washington.edu/wobbrock/pubs/mobilehci-18.pdf">$Q: A super-quick, articulation-invariant stroke-gesture recognizer for low-resource devices.</a>
			Proceedings of the ACM Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI '18).
			Barcelona, Spain (September 3-6, 2018).
			New York: ACM Press. To appear.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D. (2017).
			<a href="https://depts.washington.edu/madlab/proj/dollar/chi-17.pdf">Improving gesture recognition accuracy on touch screens for users with low vision.</a>
			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI '17).
			Denver, Colorado (May 6-11, 2017).
			New York: ACM Press, pp. 4667-4679.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D. and Wobbrock, J.O. (2016).
			<a href="http://faculty.washington.edu/wobbrock/pubs/chi-16.02.pdf">Between-subjects elicitation studies: Formalization and tool support.</a>
			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI '16).
			San Jose, California (May 7-12, 2016).
			New York: ACM Press, pp. 3390-3402.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D. and Wobbrock, J.O. (2015).
			<a href="http://faculty.washington.edu/wobbrock/pubs/chi-15.01.pdf">Formalizing agreement analysis for elicitation studies: New measures, significance test, and toolkit.</a>
			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI '15).
			Seoul, Korea (April 18-23, 2015).
			New York: ACM Press, pp. 1325-1334.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2014).
			<a href="http://faculty.washington.edu/wobbrock/pubs/icmi-14.01.pdf">Gesture heatmaps: Understanding gesture performance with colorful visualizations.</a>
			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI '14).
			Istanbul, Turkey (November 12-16, 2014).
			New York: ACM Press, pp. 172-179.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2013).
			<a href="http://faculty.washington.edu/wobbrock/pubs/icmi-13.pdf">Relative accuracy measures for stroke gestures.</a>
			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI '13).
			Sydney, Australia (December 9-13, 2013).
			New York: ACM Press, pp. 279-286.
		</li>
		<li style="font-size:10pt;">
			Anthony, L., Vatavu, R.-D. and Wobbrock, J.O. (2013).
			<a href="http://faculty.washington.edu/wobbrock/pubs/gi-13.02.pdf">Understanding the consistency of users' pen and finger stroke gesture articulation.</a>
			Proceedings of Graphics Interface (GI '13).
			Regina, Saskatchewan (May 29-31, 2013).
			Toronto, Ontario: Canadian Information Processing Society, pp. 87-94.
		</li>
		<li style="font-size:10pt;">
			Vatavu, R.-D., Anthony, L. and Wobbrock, J.O. (2012).
			<a href="http://faculty.washington.edu/wobbrock/pubs/icmi-12.pdf">Gestures as point clouds: A $P recognizer for user interface prototypes.</a>
			Proceedings of the ACM International Conference on Multimodal Interfaces (ICMI '12).
			Santa Monica, California (October 22-26, 2012).
			New York: ACM Press, pp. 273-280.
		</li>
		<li style="font-size:10pt;">
			Anthony, L. and Wobbrock, J.O. (2012).
			<a href="http://faculty.washington.edu/wobbrock/pubs/gi-12.03.pdf">$N-Protractor: A fast and accurate multistroke recognizer.</a>
			Proceedings of Graphics Interface (GI '12).
			Toronto, Ontario (May 28-30, 2012).
			Toronto, Ontario: Canadian Information Processing Society, pp. 117-120.
		</li>
		<li style="font-size:10pt;">
			Anthony, L. and Wobbrock, J.O. (2010).
			<a href="http://faculty.washington.edu/wobbrock/pubs/gi-10.02.pdf">A lightweight multistroke recognizer for user interface prototypes.</a>
			Proceedings of Graphics Interface (GI '10).
			Ottawa, Ontario (May 31-June 2, 2010).
			Toronto, Ontario: Canadian Information Processing Society, pp. 245-252.
		</li>
		<li style="font-size:10pt;background-color:lightyellow;">
			Wobbrock, J.O., Wilson, A.D. and Li, Y. (2007).
			<a href="http://faculty.washington.edu/wobbrock/pubs/uist-07.01.pdf">Gestures without libraries, toolkits or training: A $1 recognizer for user interface prototypes.</a>
			Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '07).
			Newport, Rhode Island (October 7-10, 2007).
			New York: ACM Press, pp. 159-168.
		</li>
		</ol>


		<p class="subhead">Background Publications by Others</p>
		<ol>
		<li style="font-size:10pt;">
			Li, Y. (2010).
			<a href="http://dl.acm.org/citation.cfm?id=1753654">Protractor: A fast and accurate gesture recognizer.</a>
			Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI '10).
			Atlanta, Georgia (April 10-15, 2010).
			New York: ACM Press, pp. 2169-2172.
		</li>
		<li style="font-size:10pt;">
			Kristensson, P. and Zhai, S. (2004).
			<a href="http://dl.acm.org/citation.cfm?id=1029640">SHARK<sup>2</sup>: A large vocabulary shorthand writing system for pen-based computers.</a>
			Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '04).
			Santa Fe, New Mexico (October 24-27, 2004).
			New York: ACM Press, pp. 43-52.
		</li>
		<li style="font-size:10pt;">
			Rubine, D. (1991).
			<a href="https://dl.acm.org/citation.cfm?doid=122718.122753">Specifying gestures by example.</a>
			Proceedings of the ACM Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '91).
			Las Vegas, Nevada (July 28 - August 2, 1991).
			New York: ACM Press, pp. 329-337.
		</li>
		<li style="font-size:10pt;">
			Tappert, C.C. (1982).
			<a href="http://dl.acm.org/citation.cfm?id=1664979">Cursive script recognition by elastic matching.</a>
			IBM Journal of Research and Development 26 (6), pp. 765-771.
		</li>


		<br/>
			<p style="font-size:8pt;text-align:center">
			Copyright &copy; 2007-2018 Jacob O. Wobbrock. All rights reserved. <br/>
			Last updated July 14, 2018.
			</p>
		<br/>

	</div>
</body>
</html>